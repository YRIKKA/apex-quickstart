{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APEX API Demo: Evaluating Object Detection Models\n",
    "\n",
    "This notebook demonstrates how to use YRIKKA's APEX API to evaluate object detection models in specific contexts. We'll walk through:\n",
    "\n",
    "1. Setting up your environment\n",
    "2. Packaging your model\n",
    "3. Uploading it to YRIKKA\n",
    "4. Submitting an evaluation job\n",
    "5. Getting and interpreting results\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import our required libraries and set up our API key. Make sure you have a `.env` file with your `YRIKKA_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"YRIKKA_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è Please set your YRIKKA_API_KEY in .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's set up our configuration variables. We'll be using the YOLOv8 Cherry detection example model included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "my_model_dir = \"../examples/yolo_v8_cherry\"  # Directory containing model files\n",
    "output_filename = \"model_package.tar.gz\"  # Name for our tarball\n",
    "\n",
    "# API endpoints\n",
    "presigned_url = \"https://api.yrikka.com/v1/presigned\"\n",
    "submit_job_url = \"https://api.yrikka.com/v1/submit-job\"\n",
    "job_status_url = \"https://api.yrikka.com/v1/job-status\"\n",
    "\n",
    "# Headers for API requests\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Model Package\n",
    "\n",
    "First, we'll create a tarball of our model directory. This package must include:\n",
    "- inference.py (implementing required functions)\n",
    "- model weights file\n",
    "- manifest.json\n",
    "\n",
    "The example model directory structure looks like:\n",
    "```\n",
    "yolo_v8_cherry/\n",
    "‚îú‚îÄ‚îÄ inference.py     # Implements required interface functions\n",
    "‚îú‚îÄ‚îÄ model.pt        # Your model weights\n",
    "‚îî‚îÄ‚îÄ manifest.json   # Configuration specifying entry points\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created tarball: model_package.tar.gz\n",
      "üì¶ Package size: 45.9 MB\n"
     ]
    }
   ],
   "source": [
    "def create_tarball(directory, output_file):\n",
    "    with tarfile.open(output_file, \"w:gz\") as tar:\n",
    "        tar.add(directory, arcname=os.path.basename(directory))\n",
    "    return os.path.getsize(output_file)\n",
    "\n",
    "# Create the tarball\n",
    "size_bytes = create_tarball(my_model_dir, output_filename)\n",
    "size_mb = size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"‚úÖ Created tarball: {output_filename}\")\n",
    "print(f\"üì¶ Package size: {size_mb:.1f} MB\")\n",
    "\n",
    "if size_mb > 4000:\n",
    "    print(\"‚ö†Ô∏è Warning: Package is larger than 4GB limit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get Upload URL\n",
    "\n",
    "Now we'll request a pre-signed URL from YRIKKA to upload our model package. This URL will be valid for a limited time and allows us to securely upload our model to YRIKKA's storage.\n",
    "\n",
    "The response includes:\n",
    "\n",
    "- **Upload URL**: A temporary URL for uploading your model package\n",
    "- **Package URI**: Your model's unique identifier that you'll use when submitting evaluation jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Received pre-signed URL\n",
      "üì§ Upload URL: https://yrikka-public.s3.amazonaws.com/uploads/b7e223e35cdf470cb8f2615b6845a844/model_package.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4FQXMVW7CRN4UKTG%2F20250403%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20250403T143843Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMiJHMEUCIQC45y9CfRpO4SSnVTG7gTqP1TwZlH84YkYJuQ%2BJN3uvwQIgRPhj8cm77UFV0C8CDa0gM0EOpEBeKHAWDhJl44nE9fYqhQMI8P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4MzY0OTM5NDYzMDIiDGwR1PktlmdVbv9fwCrZApK%2BPXVtmAvEi7AsSOsn9GbvDHjisBofI0W6sUwGmVDF0BLWe7bjvpWvk232fr8cRjBwZQHksP48gpnDWHCvdj0Lj4x3bbQTYaTISXDggzeqzPjBPwr5DtDGpmaYr4zz2Qbc8VH5%2BqJK9lzgXR2A07irbaVfPYWafHELedNCYy0%2FpRxeslGIs7wR9q%2Bo2LH8kZFRDRrCf9FwF%2FS3SDEFMF03X1VO3cKw%2BpxUEQfCTcnxwGY4iy8WBJG7EzYW66t6%2FZUYKvSMCZvzDKxqjT5BwkBUFJdkNm2KJCCO8A1iHV81VJfvXfLTSYFMtb7RZlUJ8Q%2FuIlIrmYX7e0v9fmazEU2JUPNPoaRC2XDIVfzi0AytkiZ2K6TO5e6o08cRsw6Myk47NJUwfLAhqs44qaOeW79IErK7vAeTrWcgfK4dgPEbiSp9Tg4%2FEOfeNJqb%2B%2BhbYzT2D6gpMAT1JDDyurq%2FBjqeAcl%2FEMau%2F1hkjtOSsKqsA7OCgfUL667Ix7%2FEzuxUlhbmvIPWqWqmCWQ2SuW98%2BGgem77wsJykkTfIE7hk%2Fyq3um6OgKx5lchTR01TaAz2i7uIjtZjy55GrzaXVwxEPpEWAC%2FKexPjrs3k75RuWBXPESUVwiGem%2FOO14DwMmpq1Y0pbK3NrdlkQoTcilcvJDskHUPRTBl1OIZevdLow1f&X-Amz-Signature=b59a92c1ae97c35da1e5cd6603b4b8a7126fe7dbf0f6f579d555c2a6a4bfb6df\n",
      "üì´ Model package will be stored at: s3://yrikka-public/uploads/b7e223e35cdf470cb8f2615b6845a844/model_package.tar.gz\n"
     ]
    }
   ],
   "source": [
    "def get_presigned_url():\n",
    "    response = requests.get(presigned_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"upload_url\"], response.json()[\"s3_uri\"]\n",
    "\n",
    "# Get the upload URL\n",
    "upload_url, model_package_uri = get_presigned_url()\n",
    "\n",
    "print(\"‚úÖ Received pre-signed URL\")\n",
    "print(f\"üì§ Upload URL: {upload_url}\")\n",
    "print(f\"üì´ Model package will be stored at: {model_package_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload Model Package\n",
    "\n",
    "Let's upload our model package using the pre-signed URL. This step might take a few minutes depending on your model size and internet connection.\n",
    "\n",
    "‚ö†Ô∏è **Important**: Your model package must be less than 4GB in size. Larger packages will be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading model package...\n",
      "‚úÖ Model package uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def upload_tarball(upload_url, file_path):\n",
    "    print(\"üì§ Uploading model package...\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        response = requests.put(upload_url, data=f)\n",
    "    response.raise_for_status()\n",
    "\n",
    "# Upload the package\n",
    "upload_tarball(upload_url, output_filename)\n",
    "print(\"‚úÖ Model package uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Submit Evaluation Job\n",
    "\n",
    "Now we'll submit our evaluation job with a detailed context description. The context description is crucial as it determines what scenarios your model will be tested in.\n",
    "\n",
    "For this example, we're testing the model's ability to detect two types of cherries in different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Job submitted successfully!\n",
      "üìã Job ID: 00cd433e-ac78-4c42-8f67-e7b2d2bad5d4\n"
     ]
    }
   ],
   "source": [
    "def submit_job(model_package_uri):\n",
    "    data = {\n",
    "        \"s3_model_package_uri\": model_package_uri,\n",
    "        \"target_classes\": [\"dark_brown_cherry\", \"green_cherry\"],\n",
    "        \"context_description\": (\n",
    "            \"Test the cherry detection model under dark and light conditions at various times of day \"\n",
    "            \"and in different weather conditions. Additionally, evaluate the model's performance in \"\n",
    "            \"detecting cherries lying on both green grass and brown dirt.\"\n",
    "        )\n",
    "    }\n",
    "    response = requests.post(submit_job_url, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"job_id\"]\n",
    "\n",
    "# Submit the job\n",
    "job_id = submit_job(model_package_uri)\n",
    "print(f\"‚úÖ Job submitted successfully!\")\n",
    "print(f\"üìã Job ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Monitor Job Progress\n",
    "\n",
    "Let's check the status of our job. Note that evaluation typically takes 20-60 minutes as APEX:\n",
    "1. Generates custom test images based on your context\n",
    "2. Runs your model on these images\n",
    "3. Analyzes performance across different scenarios\n",
    "\n",
    "The cell below will check status every 5 minutes until completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Job status message: Currently processing at node: generate_images.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: generate_images.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: Currently processing at node: evaluation_agent.\n",
      "‚è≥ Still processing...\n",
      "üîç Job status message: None\n",
      "‚úÖ Evaluation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def check_job_status(job_id):\n",
    "    while True:\n",
    "        response = requests.get(job_status_url, headers=headers, params={\"job_id\": job_id})\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        status = data.get(\"status\")\n",
    "        message = data.get(\"message\")\n",
    "\n",
    "        print(f\"üîç Job status message: {message}\")\n",
    "        \n",
    "        if status == \"SUCCESS\":\n",
    "            print(\"‚úÖ Evaluation completed successfully!\")\n",
    "            return data.get(\"results\")\n",
    "        elif status in [\"FAIL\", \"ERROR\"]:\n",
    "            print(f\"‚ùå Job failed: {message}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚è≥ Still processing...\")\n",
    "        time.sleep(300)  # Wait 5 minutes between checks\n",
    "\n",
    "# Check status and get results\n",
    "results = check_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "Let's examine our results in detail. APEX provides both aggregate metrics and granular breakdowns by context.\n",
    "\n",
    "The metrics include:\n",
    "- **Precision**: Percentage of correct detections among all detections\n",
    "- **Recall**: Percentage of actual objects that were detected\n",
    "- **F1-score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Overall Performance:\n",
      "   Precision: 0.384\n",
      "   Recall: 0.534\n",
      "   F1-score: 0.387\n",
      "\n",
      "üìà Detailed Performance by Context:\n",
      "\n",
      "LIGHTING CONDITION:\n",
      "\n",
      "   light:\n",
      "      Precision: 0.352\n",
      "      Recall: 0.551\n",
      "      F1-Score: 0.374\n",
      "\n",
      "   dark:\n",
      "      Precision: 0.593\n",
      "      Recall: 0.444\n",
      "      F1-Score: 0.508\n",
      "\n",
      "BACKGROUND:\n",
      "\n",
      "   green_grass:\n",
      "      Precision: 0.422\n",
      "      Recall: 0.559\n",
      "      F1-Score: 0.429\n",
      "\n",
      "   brown_dirt:\n",
      "      Precision: 0.349\n",
      "      Recall: 0.469\n",
      "      F1-Score: 0.348\n",
      "\n",
      "TIME OF DAY:\n",
      "\n",
      "   afternoon:\n",
      "      Precision: 0.392\n",
      "      Recall: 0.524\n",
      "      F1-Score: 0.438\n",
      "\n",
      "   morning:\n",
      "      Precision: 0.287\n",
      "      Recall: 0.235\n",
      "      F1-Score: 0.226\n",
      "\n",
      "   night:\n",
      "      Precision: 1.000\n",
      "      Recall: 0.500\n",
      "      F1-Score: 0.667\n",
      "\n",
      "   evening:\n",
      "      Precision: 0.400\n",
      "      Recall: 0.400\n",
      "      F1-Score: 0.400\n",
      "\n",
      "   not_specified:\n",
      "      Precision: 0.615\n",
      "      Recall: 0.652\n",
      "      F1-Score: 0.606\n",
      "\n",
      "WEATHER CONDITION:\n",
      "\n",
      "   foggy:\n",
      "      Precision: 0.556\n",
      "      Recall: 0.333\n",
      "      F1-Score: 0.417\n",
      "\n",
      "   cloudy:\n",
      "      Precision: 0.459\n",
      "      Recall: 0.545\n",
      "      F1-Score: 0.463\n",
      "\n",
      "   sunny:\n",
      "      Precision: 0.403\n",
      "      Recall: 0.579\n",
      "      F1-Score: 0.433\n",
      "\n",
      "   rainy:\n",
      "      Precision: 0.000\n",
      "      Recall: 0.000\n",
      "      F1-Score: 0.000\n",
      "\n",
      "   not_specified:\n",
      "      Precision: 0.600\n",
      "      Recall: 0.600\n",
      "      F1-Score: 0.600\n",
      "\n",
      "üí° Analysis Tips:\n",
      "- Look for significant variations in performance across different contexts\n",
      "- Pay attention to contexts where F1-score is particularly low\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    # Print aggregate metrics\n",
    "    print(\"üìä Overall Performance:\")\n",
    "    agg = results[\"Aggregate\"]\n",
    "    print(f\"   Precision: {agg['Precision']:.3f}\")\n",
    "    print(f\"   Recall: {agg['Recall']:.3f}\")\n",
    "    print(f\"   F1-score: {agg['F1-score']:.3f}\")\n",
    "    \n",
    "    print(\"\\nüìà Detailed Performance by Context:\")\n",
    "    for category in results[\"Granular\"]:\n",
    "        print(f\"\\n{category['Category'].upper()}:\")\n",
    "        for item in category[\"Items\"]:\n",
    "            print(f\"\\n   {item['Context']}:\")\n",
    "            print(f\"      Precision: {item['Precision']:.3f}\")\n",
    "            print(f\"      Recall: {item['Recall']:.3f}\")\n",
    "            print(f\"      F1-Score: {item['F1-Score']:.3f}\")\n",
    "            \n",
    "    print(\"\\nüí° Analysis Tips:\")\n",
    "    print(\"- Look for significant variations in performance across different contexts\")\n",
    "    print(\"- Pay attention to contexts where F1-score is particularly low\")\n",
    "else:\n",
    "    print(\"‚ùå No results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
